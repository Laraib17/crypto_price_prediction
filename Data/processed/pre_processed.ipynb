{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a90b66-ff3f-427b-b8d4-e01875b5dfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Cryptocurrency Data Processing Pipeline\\n\",\n",
    "    \"## Step 1: Data Loading and Preprocessing\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from datetime import datetime\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set display options\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"pd.set_option('display.float_format', lambda x: '%.8f' % x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load the cryptocurrency data\\n\",\n",
    "    \"df = pd.read_csv('crypto_data.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nColumn names: {df.columns.tolist()}\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nFirst few rows:\\\")\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data info and missing values\\n\",\n",
    "    \"print(\\\"Dataset Information:\\\")\\n\",\n",
    "    \"print(df.info())\\n\",\n",
    "    \"print(\\\"\\\\nMissing Values:\\\")\\n\",\n",
    "    \"print(df.isnull().sum())\\n\",\n",
    "    \"print(\\\"\\\\nBasic Statistics:\\\")\\n\",\n",
    "    \"df.describe()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data Cleaning\\n\",\n",
    "    \"# Convert Date column to datetime\\n\",\n",
    "    \"df['Date'] = pd.to_datetime(df['Date'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Handle missing values\\n\",\n",
    "    \"df = df.dropna(subset=['Close', 'Volume'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Remove duplicates\\n\",\n",
    "    \"df = df.drop_duplicates(subset=['Symbol', 'Date'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sort by Symbol and Date\\n\",\n",
    "    \"df = df.sort_values(['Symbol', 'Date']).reset_index(drop=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Cleaned dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Date range: {df['Date'].min()} to {df['Date'].max()}\\\")\\n\",\n",
    "    \"print(f\\\"Unique cryptocurrencies: {df['Symbol'].nunique()}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create technical indicators and features\\n\",\n",
    "    \"def add_technical_indicators(df):\\n\",\n",
    "    \"    df_copy = df.copy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Price features\\n\",\n",
    "    \"    df_copy['Price_Change'] = df_copy['Close'] - df_copy['Open']\\n\",\n",
    "    \"    df_copy['Price_Change_Pct'] = (df_copy['Price_Change'] / df_copy['Open']) * 100\\n\",\n",
    "    \"    df_copy['Daily_Range'] = df_copy['High'] - df_copy['Low']\\n\",\n",
    "    \"    df_copy['Volatility'] = (df_copy['Daily_Range'] / df_copy['High']) * 100\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Average price\\n\",\n",
    "    \"    df_copy['Avg_Price'] = (df_copy['High'] + df_copy['Low']) / 2\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Body size (candle)\\n\",\n",
    "    \"    df_copy['Body_Size'] = abs(df_copy['Close'] - df_copy['Open'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Upper and Lower shadows\\n\",\n",
    "    \"    df_copy['Upper_Shadow'] = df_copy['High'] - df_copy[['Open', 'Close']].max(axis=1)\\n\",\n",
    "    \"    df_copy['Lower_Shadow'] = df_copy[['Open', 'Close']].min(axis=1) - df_copy['Low']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df_copy\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_processed = add_technical_indicators(df)\\n\",\n",
    "    \"print(\\\"Technical indicators added!\\\")\\n\",\n",
    "    \"df_processed.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Add moving averages and rolling statistics\\n\",\n",
    "    \"def add_rolling_features(df, windows=[7, 14, 30]):\\n\",\n",
    "    \"    df_copy = df.copy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for window in windows:\\n\",\n",
    "    \"        # Moving averages\\n\",\n",
    "    \"        df_copy[f'MA_{window}'] = df_copy.groupby('Symbol')['Close'].transform(\\n\",\n",
    "    \"            lambda x: x.rolling(window=window, min_periods=1).mean()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Rolling volatility\\n\",\n",
    "    \"        df_copy[f'Volatility_{window}d'] = df_copy.groupby('Symbol')['Close'].transform(\\n\",\n",
    "    \"            lambda x: x.rolling(window=window, min_periods=1).std()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Rolling volume average\\n\",\n",
    "    \"        df_copy[f'Volume_MA_{window}'] = df_copy.groupby('Symbol')['Volume'].transform(\\n\",\n",
    "    \"            lambda x: x.rolling(window=window, min_periods=1).mean()\\n\",\n",
    "    \"        )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df_copy\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_processed = add_rolling_features(df_processed)\\n\",\n",
    "    \"print(\\\"Rolling features added!\\\")\\n\",\n",
    "    \"print(f\\\"Total features: {df_processed.shape[1]}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Add lag features\\n\",\n",
    "    \"def add_lag_features(df, lags=[1, 3, 7]):\\n\",\n",
    "    \"    df_copy = df.copy()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    for lag in lags:\\n\",\n",
    "    \"        df_copy[f'Close_Lag_{lag}'] = df_copy.groupby('Symbol')['Close'].shift(lag)\\n\",\n",
    "    \"        df_copy[f'Volume_Lag_{lag}'] = df_copy.groupby('Symbol')['Volume'].shift(lag)\\n\",\n",
    "    \"        df_copy[f'Return_Lag_{lag}'] = df_copy.groupby('Symbol')['Price_Change_Pct'].shift(lag)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df_copy\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_processed = add_lag_features(df_processed)\\n\",\n",
    "    \"print(\\\"Lag features added!\\\")\\n\",\n",
    "    \"df_processed.head(10)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Add time-based features\\n\",\n",
    "    \"df_processed['Year'] = df_processed['Date'].dt.year\\n\",\n",
    "    \"df_processed['Month'] = df_processed['Date'].dt.month\\n\",\n",
    "    \"df_processed['Day'] = df_processed['Date'].dt.day\\n\",\n",
    "    \"df_processed['DayOfWeek'] = df_processed['Date'].dt.dayofweek\\n\",\n",
    "    \"df_processed['Quarter'] = df_processed['Date'].dt.quarter\\n\",\n",
    "    \"df_processed['DayOfYear'] = df_processed['Date'].dt.dayofyear\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Time-based features added!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Save Processed Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save the processed dataset\\n\",\n",
    "    \"df_processed.to_csv('crypto_data_processed.csv', index=False)\\n\",\n",
    "    \"print(\\\"Processed data saved to 'crypto_data_processed.csv'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save statistics per coin\\n\",\n",
    "    \"coin_stats = df_processed.groupby('Symbol').agg({\\n\",\n",
    "    \"    'Name': 'first',\\n\",\n",
    "    \"    'Close': ['mean', 'std', 'min', 'max'],\\n\",\n",
    "    \"    'Volume': ['mean', 'sum'],\\n\",\n",
    "    \"    'Volatility': 'mean',\\n\",\n",
    "    \"    'Price_Change_Pct': ['mean', 'std'],\\n\",\n",
    "    \"    'Date': ['min', 'max', 'count']\\n\",\n",
    "    \"}).reset_index()\\n\",\n",
    "    \"\\n\",\n",
    "    \"coin_stats.columns = ['_'.join(col).strip('_') for col in coin_stats.columns.values]\\n\",\n",
    "    \"coin_stats.to_csv('coin_statistics.csv', index=False)\\n\",\n",
    "    \"print(\\\"Coin statistics saved to 'coin_statistics.csv'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFinal processed dataset shape: {df_processed.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Total features: {df_processed.shape[1]}\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
